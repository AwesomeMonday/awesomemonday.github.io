I"µ%<p>Hello, this is Hao.</p>

<p>As I was looking for more projects to practice, I came across with this virtual experience programe on <a href="https://www.theforage.com/" target="_blank">theforage.com</a>. The project is hosted by Accenture North America, and itâ€™s called Navigating Numbers (full details can be found <a href="https://www.theforage.com/virtual-internships/prototype/hzmoNKtzvAzXsEqx8/Data-Analytics-Virtual-Experience?ref=9W3J5sbu3KKhpJDGr" target="_blank">here</a>).</p>

<p>load in the libraries</p>

<pre><code class="language-{r}">library(tidyverse)
library(Hmisc)
library(lubridate)
library(janitor)
</code></pre>

<p>load in the data sets</p>

<pre><code class="language-{r}">rm(list = ls())
content &lt;- read_csv("https://cdn.theforage.com/vinternships/companyassets/T6kdcdKSTfg2aotxT/Content%20(1).csv")

location &lt;- read_csv("https://cdn.theforage.com/vinternships/companyassets/T6kdcdKSTfg2aotxT/Location%20(1).csv")

profile &lt;- read_csv("https://cdn.theforage.com/vinternships/companyassets/T6kdcdKSTfg2aotxT/Profile%20(1).csv")

reaction &lt;- read_csv("https://cdn.theforage.com/vinternships/companyassets/T6kdcdKSTfg2aotxT/Reactions%20(1).csv")

reaction_types &lt;- read_csv("https://cdn.theforage.com/vinternships/companyassets/T6kdcdKSTfg2aotxT/ReactionTypes%20(1).csv")

session &lt;- read_csv("https://cdn.theforage.com/vinternships/companyassets/T6kdcdKSTfg2aotxT/Session%20(1).csv")

user &lt;- read_csv("https://cdn.theforage.com/vinternships/companyassets/T6kdcdKSTfg2aotxT/User%20(1).csv")
</code></pre>

<ol>
  <li>content data set
log: removed unnecessary columns, and clean col names; cleaned category names;
this data set will join with other sets on content_id and user_id</li>
</ol>

<pre><code class="language-{r}"># use describe function to see if there are any missing values
describe(content)

content &lt;- content %&gt;% 
  select(-"URL", -...1) %&gt;% 
  clean_names()

glimpse(content)


# some category has quotes on them and some don't, remove marks and change to lower case to keep consistency

content &lt;- content %&gt;% 
  mutate(category = gsub('[\"]', '', category)) %&gt;% 
  mutate(category = tolower(category)) %&gt;% 
  mutate(category = fct_recode(category, "public_speaking" = "public speaking"),
         category = fct_recode(category, "healthy_eating" = "healthy eating"))

# rename some of the column names to prepare for joining datasets
content &lt;- content %&gt;% 
  rename(content_type = type)

# initial exploration of the 'content' dataset
content %&gt;% 
  count(category, sort = TRUE) %&gt;% 
  View()

# top 5 categories by content category
content %&gt;% 
  mutate(category = fct_lump(category, 5)) %&gt;% 
  group_by(category) %&gt;% 
  summarise(total = n()) %&gt;% 
  arrange(desc(total))

# distribution of categories
content %&gt;% 
  group_by(category) %&gt;% 
  summarise(n = n()) %&gt;% 
  mutate(category = fct_reorder(category, n),) %&gt;% 
  ggplot(aes(category, n, fill = category)) +
  geom_col(show.legend = FALSE) +
  coord_flip() +
  labs(title = "rank on category by the number of posts", y = 'number of posts', x = '')


# distribution of content_type 
content %&gt;% 
  group_by(content_type) %&gt;% 
  summarise(n = n()) %&gt;% 
  mutate(content_type = fct_reorder(content_type, n)) %&gt;% 
  ggplot(aes(content_type, n, fill = content_type)) +
  geom_col(show.legend = FALSE) +
  coord_flip()+
  labs(title = 'rank on content_type by the number of posts', y = 'number of posts', x = '')
</code></pre>

<p>2.location data set
log: removed unnecessary columns and cleaned col names; extracted zip code and state name from address then dropped address column
this set will join with user data set on user_id to view the state distribution on map</p>

<pre><code class="language-{r}">describe(location)

location &lt;- location %&gt;% 
  select(-...1) %&gt;% 
  clean_names()

#extract state and zip code from address then drop address column
location &lt;- location %&gt;% 
  mutate(zip_code = str_sub(address, -5),
         state = str_sub(address, -8, -7)) %&gt;% 
  select(-address)

# initial exploration of the 2 new columns
location %&gt;% 
  count(state, sort = TRUE) %&gt;% 
  View()
location %&gt;% 
  count(zip_code, sort = TRUE)
glimpse(location)
</code></pre>

<ol>
  <li>profile
log: separated interests into individual rows, removed marks and corrected spelling error, and dropped age column
this set will NOT be used to join with other datasets for the final csv</li>
</ol>

<pre><code class="language-{r}">describe(profile)

profile &lt;- profile %&gt;% 
  select(-'...1', -'Age')

profile &lt;- profile %&gt;% 
  separate_rows(Interests, sep = ',') %&gt;% 
  mutate(Interests = str_replace(Interests, "\\'", "")) %&gt;%   
  mutate(Interests = str_replace(Interests, "\\[", "")) %&gt;%   
  mutate(Interests = str_replace(Interests, "\\]", "")) %&gt;%   
  mutate(Interests = str_replace(Interests, "\\'", "")) %&gt;%   
  mutate(Interests = str_replace(Interests, " ", "")) %&gt;% 
  clean_names() 

# recode some of the misspelled names
profile &lt;- profile %&gt;% 
  mutate(interests = fct_recode(interests, "public_speaking" = "public speaking"),
         interests = fct_recode(interests, "public_speaking" = "publicspeaking"),
         interests = fct_recode(interests, "healthy_eating" = "healthy eating"),
         interests = fct_recode(interests, "healthy_eating" = "healthyeating")) 

profile %&gt;% 
  count(interests, sort = TRUE)
</code></pre>

<ol>
  <li>reaction
log: removed unnecessary columns and cleaned col names; extracted time info for future analysis; 
dropped the user_id column since it refers the user that interacted with the content, not the user who created it; 
this set will join with reaction_types on type to get the scores of each content thru group by</li>
</ol>

<pre><code class="language-{r}">describe(reaction) 

# looking into datetime column, extracting the month, day, weekday and hour info for initial exploration in R
reaction &lt;- reaction %&gt;% 
  mutate(Month = month(Datetime, label = TRUE),
         Day = day(Datetime),
         Weekday = wday(Datetime, label = TRUE),
         Hour = hour(Datetime)) %&gt;% 
  clean_names() %&gt;%
  select(-(x1), -(user_id)) 
  
reaction &lt;- reaction %&gt;% 
  rename(reaction_type = type) 

# reaction type distribution
reaction %&gt;% 
  filter(!is.na(reaction_type)) %&gt;% 
  group_by(reaction_type) %&gt;% 
  summarise(total = n()) %&gt;% 
  mutate(reaction_type = fct_reorder(reaction_type, total)) %&gt;% 
  ggplot(aes(total, reaction_type, fill = reaction_type))+
  geom_col(show.legend = F) +
  labs(title = 'reaction type distribution', x = 'number of reactions', y = '')
 
# initial exploration on the time variables
reaction %&gt;% 
  group_by(month) %&gt;% 
  summarise(total = n()) %&gt;% 
  ggplot(aes(month, total, group = 1))+
  geom_line()+
  expand_limits(y = 0)+
  labs(title = 'reactoin count by month', x = '', y = '')

reaction %&gt;% 
  group_by(weekday) %&gt;% 
  summarise(total = n()) %&gt;% 
  ggplot(aes(weekday, total, group = 1))+
  geom_line()+
  expand_limits(y = 0)+
  labs(title = 'reaction count by weekday', x = '', y = '')

reaction %&gt;% 
  group_by(hour) %&gt;% 
  summarise(total = n()) %&gt;% 
  ggplot(aes(hour, total, group = 1))+
  geom_line()+
  expand_limits(y = 0)+
  labs(title = 'reaction count by hour', x = '', y = '')
</code></pre>

<ol>
  <li>reaction_types
log: removed unnecessary columns and cleaned col names; 
this set will join reaction data set and use the score to rank the top 5 categories that is in the task</li>
</ol>

<pre><code class="language-{r}">reaction_types &lt;- reaction_types %&gt;% 
  select(-"...1")

reaction_types &lt;- reaction_types %&gt;% 
  clean_names() %&gt;%
  rename(reaction_type = type)

# what kind of reaction_types have high scores
reaction_types %&gt;% 
  arrange(desc(score))

# sentiment distribution
reaction_types %&gt;%
  count(sentiment, sort = TRUE)
</code></pre>

<ol>
  <li>session
log: removed unnecessary columns and cleaned names; 
this data set can provide us some interesting insights on device usage, but itâ€™s not ralevant to the analysis this time</li>
</ol>

<pre><code class="language-{r}">session &lt;- session %&gt;% 
  select(-...1) %&gt;% 
  clean_names()
</code></pre>

<ol>
  <li>user data set
log: removed unnecessary columns and cleaned column names
we donâ€™t need the user info for our business task</li>
</ol>

<pre><code class="language-{r}">user &lt;- user %&gt;% 
  select(-...1) %&gt;% 
  clean_names()
</code></pre>

<p>since the business task is to find out the top 5 most popular categories, it should be based on the content reactions, but the count of how many posts
of content in each category. I will use the score to calculate the ranks.</p>

<pre><code class="language-{r}"># first let's join the tables

buzz_full &lt;- location %&gt;% 
  right_join(content, by = 'user_id') %&gt;% 
  left_join(reaction, by = 'content_id') %&gt;% 
  left_join(reaction_types, by = 'reaction_type')

# export the dataset for future analysis
# write.csv(buzz_full, "C:\\Users\\haoli\\Desktop\\buzz_full.csv")

# then we can use the aggregated score to rank the categories
buzz_full %&gt;% 
  group_by(category) %&gt;% 
  summarise(total_score = sum(score, na.rm = T)) %&gt;% 
  arrange(desc(total_score))

# the top 5 categories are: animals, science, healthy_eating, technology, food
social_buzz_top5 &lt;- buzz_full %&gt;% 
  filter(category %in% c("animals", "science", "healthy_eating", "technology", "food"))
# write.csv(social_buzz_top5, "C:\\Users\\haoli\\Desktop\\social_buzz_top5.csv")
</code></pre>

:ET